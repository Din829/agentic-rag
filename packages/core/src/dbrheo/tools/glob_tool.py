"""
Globå·¥å…· - æ™ºèƒ½æ–‡ä»¶å‘ç°
å€Ÿé‰´Gemini CLIçš„æ—¶é—´æ„ŸçŸ¥æ’åºå’Œé«˜æ•ˆæ–‡ä»¶åŒ¹é…
"""

import os
import fnmatch
import time
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
import asyncio

from ..types.tool_types import ToolResult
from ..types.core_types import AbortSignal
from .base import Tool
from ..config.base import AgentConfig
from ..utils.debug_logger import DebugLogger, log_info


@dataclass
class FileEntry:
    """æ–‡ä»¶æ¡ç›®ä¿¡æ¯"""
    path: str
    name: str
    size: int
    modified_time: float
    is_directory: bool
    relative_path: str


class GlobTool(Tool):
    """
    æ™ºèƒ½æ–‡ä»¶å‘ç°å·¥å…·
    
    æ ¸å¿ƒç‰¹æ€§ï¼ˆå‚è€ƒGemini CLIï¼‰ï¼š
    1. æ—¶é—´æ„ŸçŸ¥æ’åºï¼šæœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ä¼˜å…ˆ
    2. æ”¯æŒå¤æ‚globæ¨¡å¼ï¼š*, **, ?, []
    3. æ™ºèƒ½å¿½ç•¥ï¼šè‡ªåŠ¨è¯†åˆ«.gitignoreç­‰
    4. æ€§èƒ½ä¼˜åŒ–ï¼šé™åˆ¶æœç´¢æ·±åº¦å’Œç»“æœæ•°
    5. è·¨å¹³å°å…¼å®¹ï¼šå¤„ç†ä¸åŒç³»ç»Ÿçš„è·¯å¾„å·®å¼‚
    """
    
    # é»˜è®¤å¿½ç•¥çš„ç›®å½•ï¼ˆæé«˜æ€§èƒ½ï¼‰
    DEFAULT_IGNORE_DIRS = {
        '.git', '__pycache__', 'node_modules', '.idea', '.vscode',
        'dist', 'build', 'target', '.cache', '.pytest_cache',
        'venv', 'env', '.env', 'virtualenv', '.venv'
    }
    
    # é»˜è®¤å¿½ç•¥çš„æ–‡ä»¶æ¨¡å¼
    DEFAULT_IGNORE_FILES = {
        '*.pyc', '*.pyo', '*.swp', '*.swo', '.DS_Store',
        'Thumbs.db', '*.class', '*.o', '*.so', '*.dll'
    }
    
    # æ—¶é—´é˜ˆå€¼ï¼ˆ7å¤©å†…çš„æ–‡ä»¶è¢«è®¤ä¸ºæ˜¯"æœ€è¿‘çš„"ï¼‰
    RECENCY_THRESHOLD_DAYS = 7
    
    def __init__(self, config: AgentConfig, i18n=None):
        self._i18n = i18n
        
        super().__init__(
            name="glob",
            display_name=self._('glob_tool_name', default="æ–‡ä»¶æŸ¥æ‰¾") if i18n else "æ–‡ä»¶æŸ¥æ‰¾",
            description="""Find files matching glob patterns. Returns files sorted by relevance (recent files first).
Supports patterns like '*.py', '**/*.js', 'src/**/test_*.py'.
MUCH faster than manually listing directories.
Best practice: Use glob to find files, not manual directory traversal.""",
            parameter_schema={
                "type": "object",
                "properties": {
                    "pattern": {
                        "type": "string",
                        "description": "Glob pattern to match files (e.g., '*.py', '**/*.js', 'src/**/*.ts')"
                    },
                    "path": {
                        "type": "string",
                        "description": "Base path to search from. Defaults to current directory",
                        "default": "."
                    },
                    "case_sensitive": {
                        "type": "boolean",
                        "description": "Case sensitive matching",
                        "default": True
                    },
                    "include_dirs": {
                        "type": "boolean",
                        "description": "Include directories in results",
                        "default": False
                    },
                    "respect_gitignore": {
                        "type": "boolean",
                        "description": "Respect .gitignore rules",
                        "default": True
                    },
                    "max_results": {
                        "type": "integer",
                        "description": "Maximum number of results to return",
                        "default": 100,
                        "minimum": 1,
                        "maximum": 1000
                    },
                    "max_depth": {
                        "type": "integer",
                        "description": "Maximum directory depth to search",
                        "default": 10,
                        "minimum": 1,
                        "maximum": 20
                    }
                },
                "required": ["pattern"]
            },
            is_output_markdown=True,
            should_summarize_display=True,
            i18n=i18n
        )
        self.config = config
        self._gitignore_cache = {}
    
    def validate_tool_params(self, params: Dict[str, Any]) -> Optional[str]:
        """éªŒè¯å‚æ•°"""
        pattern = params.get("pattern", "")
        if not pattern:
            return self._('glob_pattern_empty', default="File pattern cannot be empty")
        
        # éªŒè¯è·¯å¾„
        path = params.get("path", ".")
        if not os.path.exists(path):
            return self._('glob_path_not_found', default=f"Path not found: {path}")
        
        return None
    
    async def execute(
        self,
        params: Dict[str, Any],
        signal: AbortSignal,
        update_output: Optional[Any] = None
    ) -> ToolResult:
        """æ‰§è¡Œæ–‡ä»¶æŸ¥æ‰¾"""
        pattern = params.get("pattern")
        base_path = params.get("path", ".")
        case_sensitive = params.get("case_sensitive", True)
        include_dirs = params.get("include_dirs", False)
        respect_gitignore = params.get("respect_gitignore", True)
        max_results = params.get("max_results", 100)
        max_depth = params.get("max_depth", 10)
        
        try:
            # è§„èŒƒåŒ–åŸºç¡€è·¯å¾„
            base_path = Path(base_path).resolve()
            
            # åŠ è½½gitignoreè§„åˆ™
            gitignore_patterns = []
            if respect_gitignore:
                gitignore_patterns = await self._load_gitignore_patterns(base_path)
            
            # æ‰§è¡Œæ–‡ä»¶æœç´¢
            matches = await self._find_files(
                pattern, base_path, case_sensitive, include_dirs,
                gitignore_patterns, max_results, max_depth, signal
            )
            
            # æ™ºèƒ½æ’åºï¼ˆå‚è€ƒGemini CLIï¼‰
            sorted_matches = self._sort_by_relevance(matches)
            
            # é™åˆ¶ç»“æœæ•°
            if len(sorted_matches) > max_results:
                sorted_matches = sorted_matches[:max_results]
            
            # æ ¼å¼åŒ–ç»“æœ
            return self._format_results(sorted_matches, pattern, base_path)
            
        except asyncio.CancelledError:
            return ToolResult(
                error=self._('glob_cancelled', default="File search cancelled by user")
            )
        except Exception as e:
            return ToolResult(
                error=self._('glob_error', default=f"File search failed: {str(e)}")
            )
    
    async def _find_files(
        self, pattern: str, base_path: Path, case_sensitive: bool,
        include_dirs: bool, gitignore_patterns: List[str],
        max_results: int, max_depth: int, signal: AbortSignal
    ) -> List[FileEntry]:
        """é€’å½’æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶"""
        matches = []
        
        # å¤„ç†globæ¨¡å¼
        # ** è¡¨ç¤ºé€’å½’æ‰€æœ‰å­ç›®å½•
        if '**' in pattern:
            recursive = True
            # å°† ** è½¬æ¢ä¸ºå…·ä½“çš„æœç´¢é€»è¾‘
            pattern_parts = pattern.split('**')
        else:
            recursive = False
            pattern_parts = [pattern]
        
        # ä½¿ç”¨asyncioæé«˜æ€§èƒ½
        async def process_directory(dir_path: Path, depth: int):
            if signal and signal.aborted:
                return
            
            if depth > max_depth:
                return
            
            try:
                for entry in os.scandir(dir_path):
                    if signal and signal.aborted:
                        break
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥
                    if self._should_ignore(entry.path, entry.is_dir(), gitignore_patterns):
                        continue
                    
                    # è·å–ç›¸å¯¹è·¯å¾„
                    rel_path = os.path.relpath(entry.path, base_path)
                    
                    # åŒ¹é…æ£€æŸ¥
                    if self._match_pattern(entry.name, rel_path, pattern, case_sensitive, recursive):
                        if entry.is_dir():
                            if include_dirs:
                                stat = entry.stat()
                                matches.append(FileEntry(
                                    path=entry.path,
                                    name=entry.name,
                                    size=0,
                                    modified_time=stat.st_mtime,
                                    is_directory=True,
                                    relative_path=rel_path
                                ))
                        else:
                            stat = entry.stat()
                            matches.append(FileEntry(
                                path=entry.path,
                                name=entry.name,
                                size=stat.st_size,
                                modified_time=stat.st_mtime,
                                is_directory=False,
                                relative_path=rel_path
                            ))
                            
                            if len(matches) >= max_results * 2:  # æ”¶é›†é¢å¤–çš„ç”¨äºæ’åº
                                return
                    
                    # é€’å½’å¤„ç†å­ç›®å½•
                    if entry.is_dir() and (recursive or depth == 0):
                        await process_directory(Path(entry.path), depth + 1)
                        
            except PermissionError:
                # å¿½ç•¥æ²¡æœ‰æƒé™çš„ç›®å½•
                if DebugLogger.should_log("DEBUG"):
                    log_info("GlobTool", f"Permission denied: {dir_path}")
            except Exception as e:
                if DebugLogger.should_log("DEBUG"):
                    log_info("GlobTool", f"Error processing {dir_path}: {e}")
        
        # å¼€å§‹æœç´¢
        await process_directory(base_path, 0)
        
        return matches
    
    def _match_pattern(self, name: str, rel_path: str, pattern: str, 
                      case_sensitive: bool, recursive: bool) -> bool:
        """åŒ¹é…æ–‡ä»¶åæˆ–è·¯å¾„"""
        # å¤„ç†å¤§å°å†™
        if not case_sensitive:
            name = name.lower()
            rel_path = rel_path.lower()
            pattern = pattern.lower()
        
        # å¦‚æœæ¨¡å¼åŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼ŒåŒ¹é…å®Œæ•´è·¯å¾„
        if '/' in pattern or os.sep in pattern:
            return fnmatch.fnmatch(rel_path, pattern)
        
        # å¤„ç† ** é€’å½’æ¨¡å¼
        if '**' in pattern:
            # ä¾‹å¦‚: **/*.py åŒ¹é…æ‰€æœ‰å­ç›®å½•ä¸­çš„.pyæ–‡ä»¶
            parts = pattern.split('**')
            if len(parts) == 2:
                prefix = parts[0].strip('/')
                suffix = parts[1].strip('/')
                
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ¹é…
                if prefix and not rel_path.startswith(prefix):
                    return False
                if suffix:
                    # æ£€æŸ¥æ–‡ä»¶åæˆ–è·¯å¾„åç¼€
                    if '/' in suffix:
                        return fnmatch.fnmatch(rel_path, f"*{suffix}")
                    else:
                        return fnmatch.fnmatch(name, suffix)
                return True
        
        # ç®€å•æ–‡ä»¶ååŒ¹é…
        return fnmatch.fnmatch(name, pattern)
    
    def _should_ignore(self, path: str, is_dir: bool, gitignore_patterns: List[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥æ–‡ä»¶/ç›®å½•"""
        name = os.path.basename(path)
        
        # æ£€æŸ¥é»˜è®¤å¿½ç•¥çš„ç›®å½•
        if is_dir and name in self.DEFAULT_IGNORE_DIRS:
            return True
        
        # æ£€æŸ¥é»˜è®¤å¿½ç•¥çš„æ–‡ä»¶
        if not is_dir:
            for pattern in self.DEFAULT_IGNORE_FILES:
                if fnmatch.fnmatch(name, pattern):
                    return True
        
        # æ£€æŸ¥gitignoreè§„åˆ™
        for pattern in gitignore_patterns:
            if fnmatch.fnmatch(name, pattern):
                return True
        
        return False
    
    async def _load_gitignore_patterns(self, base_path: Path) -> List[str]:
        """åŠ è½½.gitignoreè§„åˆ™"""
        patterns = []
        
        # æŸ¥æ‰¾.gitignoreæ–‡ä»¶
        gitignore_path = base_path / ".gitignore"
        if gitignore_path.exists():
            try:
                with open(gitignore_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        # å¿½ç•¥ç©ºè¡Œå’Œæ³¨é‡Š
                        if line and not line.startswith('#'):
                            # ç®€åŒ–gitignoreè§„åˆ™ï¼ˆä¸å®Œå…¨å®ç°ï¼‰
                            pattern = line.rstrip('/')
                            if pattern.startswith('/'):
                                pattern = pattern[1:]
                            patterns.append(pattern)
            except Exception as e:
                if DebugLogger.should_log("DEBUG"):
                    log_info("GlobTool", f"Failed to read .gitignore: {e}")
        
        # ä¹Ÿæ£€æŸ¥.geminiignoreæˆ–.agentignore
        agentignore_path = base_path / ".agentignore"
        if agentignore_path.exists():
            try:
                with open(agentignore_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            patterns.append(line.rstrip('/'))
            except:
                pass
        
        return patterns
    
    def _sort_by_relevance(self, files: List[FileEntry]) -> List[FileEntry]:
        """
        æ™ºèƒ½æ’åºæ–‡ä»¶ï¼ˆå‚è€ƒGemini CLIï¼‰
        1. æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ä¼˜å…ˆï¼ˆ7å¤©å†…ï¼‰
        2. æ—§æ–‡ä»¶æŒ‰å­—æ¯é¡ºåº
        """
        now = time.time()
        recency_threshold = now - (self.RECENCY_THRESHOLD_DAYS * 24 * 60 * 60)
        
        recent_files = []
        old_files = []
        
        for file in files:
            if file.modified_time > recency_threshold:
                recent_files.append(file)
            else:
                old_files.append(file)
        
        # æœ€è¿‘çš„æ–‡ä»¶æŒ‰ä¿®æ”¹æ—¶é—´é™åº
        recent_files.sort(key=lambda f: f.modified_time, reverse=True)
        
        # æ—§æ–‡ä»¶æŒ‰è·¯å¾„å­—æ¯é¡ºåº
        old_files.sort(key=lambda f: f.relative_path.lower())
        
        # åˆå¹¶ç»“æœ
        return recent_files + old_files
    
    def _format_results(self, matches: List[FileEntry], pattern: str, base_path: Path) -> ToolResult:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not matches:
            return ToolResult(
                summary=self._('glob_no_matches', default=f"No files found matching: {pattern}"),
                llm_content=self._('glob_no_matches_llm', default=f"No files found matching pattern '{pattern}'"),
                return_display=self._('glob_no_matches_display', default="ğŸ“ No matching files found")
            )
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_size = sum(f.size for f in matches if not f.is_directory)
        dir_count = sum(1 for f in matches if f.is_directory)
        file_count = len(matches) - dir_count
        
        # æ„å»ºLLMå†…å®¹ï¼ˆè¯¦ç»†åˆ—è¡¨ï¼‰
        llm_lines = [f"Found {len(matches)} items matching '{pattern}':"]
        
        # åˆ†ç»„æ˜¾ç¤º
        if dir_count > 0:
            llm_lines.append(f"\nDirectories ({dir_count}):")
            for entry in matches:
                if entry.is_directory:
                    llm_lines.append(f"  ğŸ“ {entry.relative_path}/")
        
        if file_count > 0:
            llm_lines.append(f"\nFiles ({file_count}):")
            for entry in matches:
                if not entry.is_directory:
                    mod_time = datetime.fromtimestamp(entry.modified_time)
                    time_str = mod_time.strftime("%Y-%m-%d %H:%M")
                    size_str = self._format_size(entry.size)
                    llm_lines.append(f"  ğŸ“„ {entry.relative_path} ({size_str}, {time_str})")
        
        # æ„å»ºæ˜¾ç¤ºå†…å®¹ï¼ˆç®€æ´æ‘˜è¦ï¼‰
        display_lines = [
            f"ğŸ” Pattern: {pattern}",
            f"ğŸ“Š Results: {file_count} files, {dir_count} directories"
        ]
        
        if total_size > 0:
            display_lines.append(f"ğŸ’¾ Total size: {self._format_size(total_size)}")
        
        # æ—¶é—´ç»Ÿè®¡
        now = time.time()
        recency_threshold = now - (self.RECENCY_THRESHOLD_DAYS * 24 * 60 * 60)
        recent_count = sum(1 for f in matches if f.modified_time > recency_threshold)
        if recent_count > 0:
            display_lines.append(f"ğŸ• Recent files (7 days): {recent_count}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœ
        display_lines.append("\nğŸ“ Sample results:")
        for entry in matches[:10]:
            if entry.is_directory:
                display_lines.append(f"  ğŸ“ {entry.relative_path}/")
            else:
                display_lines.append(f"  ğŸ“„ {entry.relative_path}")
        
        if len(matches) > 10:
            display_lines.append(f"  ... and {len(matches) - 10} more")
        
        return ToolResult(
            summary=self._('glob_summary', default=f"Found {len(matches)} items matching '{pattern}'"),
            llm_content="\n".join(llm_lines),
            return_display="\n".join(display_lines)
        )
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f}TB"
    
    def get_description(self, params: Dict[str, Any]) -> str:
        """è·å–æ“ä½œæè¿°"""
        pattern = params.get("pattern", "")
        path = params.get("path", ".")
        
        desc = self._('glob_description', default=f"Find files matching '{pattern}'")
        if path != ".":
            desc += f" in {path}"
        
        return desc
    
    async def should_confirm_execute(self, params: Dict[str, Any], signal: AbortSignal) -> Optional[Any]:
        """æ–‡ä»¶æŸ¥æ‰¾é€šå¸¸ä¸éœ€è¦ç¡®è®¤"""
        return False