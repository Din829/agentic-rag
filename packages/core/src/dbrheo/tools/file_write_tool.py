"""
æ–‡ä»¶å†™å…¥å·¥å…· - æ”¯æŒæ•°æ®åº“æŸ¥è¯¢ç»“æœå¯¼å‡ºã€æŠ¥å‘Šç”Ÿæˆç­‰
å€Ÿé‰´Gemini CLIçš„ç¡®è®¤æœºåˆ¶å’Œå®‰å…¨è®¾è®¡
"""

import os
import json
import csv
import yaml
import asyncio
import aiofiles
import difflib
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass

from ..types.tool_types import ToolResult
from ..types.core_types import AbortSignal
from ..types.file_types import (
    FileFormat, ApprovalMode, FileWriteConfirmationDetails,
    FileOperationResult, StreamingConfig
)
from .base import Tool
from ..config.base import AgentConfig


class FileWriteTool(Tool):
    """
    å¢å¼ºçš„æ–‡ä»¶å†™å…¥å·¥å…·ï¼Œæ”¯æŒï¼š
    - å¤šç§æ–‡ä»¶æ ¼å¼ï¼ˆCSVã€JSONã€Excelã€SQLç­‰ï¼‰
    - æµå¼å†™å…¥å¤§æ•°æ®
    - æ™ºèƒ½ç¡®è®¤æœºåˆ¶ï¼ˆå€Ÿé‰´Gemini CLIï¼‰
    - æ•°æ®åº“æŸ¥è¯¢ç»“æœå¯¼å‡º
    - è¿›åº¦åé¦ˆå’Œé”™è¯¯æ¢å¤
    """
    
    # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼å’Œæ‰©å±•åæ˜ å°„
    FORMAT_EXTENSIONS = {
        FileFormat.CSV: ['.csv', '.tsv'],
        FileFormat.JSON: ['.json', '.jsonl'],
        FileFormat.EXCEL: ['.xlsx', '.xls'],
        FileFormat.SQL: ['.sql'],
        FileFormat.MARKDOWN: ['.md', '.markdown'],
        FileFormat.TEXT: ['.txt', '.log'],
        FileFormat.PARQUET: ['.parquet'],
        FileFormat.YAML: ['.yaml', '.yml'],
        FileFormat.XML: ['.xml']
    }
    
    # æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆ100MBï¼‰
    MAX_FILE_SIZE = 100 * 1024 * 1024
    
    def __init__(self, config: AgentConfig, i18n=None):
        # å…ˆä¿å­˜i18nå®ä¾‹ï¼Œä»¥ä¾¿åœ¨åˆå§‹åŒ–æ—¶ä½¿ç”¨
        self._i18n = i18n
        
        super().__init__(
            name="write_file",
            display_name=self._('file_write_tool_name', default="æ–‡ä»¶å†™å…¥") if i18n else "æ–‡ä»¶å†™å…¥",
            description="Writes files with intelligent format detection and automatic error recovery. Creates directories when needed, handles format conversions, and ensures reliable file operations with comprehensive progress feedback.",
            parameter_schema={
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "Absolute file path to write. Must be within allowed directories."
                    },
                    "content": {
                        "type": "string",
                        "description": "Content to write. For structured data, provide JSON string."
                    },
                    "format": {
                        "type": "string",
                        "enum": [f.value for f in FileFormat],
                        "description": "Output format. Auto-detected from extension if not specified."
                    },
                    "mode": {
                        "type": "string",
                        "enum": ["overwrite", "append", "create_new"],
                        "description": "Write mode. 'create_new' fails if file exists.",
                        "default": "overwrite"
                    },
                    "encoding": {
                        "type": "string",
                        "description": "File encoding (auto for system default). Common: utf-8, cp932 (Japanese), gbk (Chinese)",
                        "default": "auto"
                    },
                    "compression": {
                        "type": "string",
                        "enum": ["none", "gzip", "bz2", "xz"],
                        "description": "Compression type",
                        "default": "none"
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Optional metadata like source SQL, tables, etc.",
                        "properties": {
                            "source_sql": {"type": "string"},
                            "source_tables": {"type": "array", "items": {"type": "string"}},
                            "row_count": {"type": "integer"},
                            "created_by": {"type": "string"}
                        }
                    }
                },
                "required": ["path", "content"]
            },
            is_output_markdown=True,
            can_update_output=True,
            should_summarize_display=True,
            i18n=i18n  # ä¼ é€’i18nç»™åŸºç±»
        )
        
        self.config = config
        
        # å®¡æ‰¹æ¨¡å¼ï¼Œé»˜è®¤æ‰‹åŠ¨
        self.approval_mode = ApprovalMode(config.get("file_approval_mode", "manual"))
        
        # åŠ¨æ€æ£€æµ‹ç³»ç»Ÿå¹¶è®¾ç½®çµæ´»çš„è®¿é—®æƒé™
        default_paths = self._get_system_paths(config)
        self.allowed_paths = config.get("file_allowed_paths", default_paths)
        
        # æµå¼å¤„ç†é…ç½®
        self.streaming_config = StreamingConfig(
            chunk_size=config.get("file_streaming_chunk_size", 10000),
            memory_limit_mb=config.get("file_memory_limit_mb", 100),
            enable_compression=config.get("file_enable_compression", True)
        )
    
    def validate_tool_params(self, params: Dict[str, Any]) -> Optional[str]:
        """éªŒè¯å‚æ•°"""
        path = params.get("path", "")
        if not path:
            return self._('file_write_path_empty', default="File path cannot be empty")
        
        # å¿…é¡»æ˜¯ç»å¯¹è·¯å¾„
        if not os.path.isabs(path):
            return self._('file_write_path_not_absolute', default="Path must be absolute")
        
        # å†…å®¹ä¸èƒ½ä¸ºç©ºï¼ˆé™¤éæ˜¯åˆ›å»ºç©ºæ–‡ä»¶ï¼‰
        content = params.get("content")
        if content is None:
            return self._('file_write_content_none', default="Content cannot be None")
        
        return None
    
    def get_description(self, params: Dict[str, Any]) -> str:
        """è·å–æ“ä½œæè¿°"""
        path = Path(params.get("path", ""))
        mode = params.get("mode", "overwrite")
        # å¤„ç†æ ¼å¼å‚æ•°
        format_param = params.get("format")
        if format_param and isinstance(format_param, str):
            format_str = format_param.upper()
        else:
            format = format_param if format_param else self._detect_format(path)
            format_str = format.value.upper() if isinstance(format, FileFormat) else str(format).upper()
        
        action = {
            "overwrite": self._('file_write_action_overwrite', default="å†™å…¥"),
            "append": self._('file_write_action_append', default="è¿½åŠ åˆ°"),
            "create_new": self._('file_write_action_create', default="åˆ›å»º")
        }.get(mode, self._('file_write_action_overwrite', default="å†™å…¥"))
        
        return self._('file_write_description', default="{action}{format}æ–‡ä»¶: {filename}", action=action, format=format_str, filename=path.name)
    
    async def should_confirm_execute(
        self,
        params: Dict[str, Any],
        signal: AbortSignal
    ) -> Union[bool, FileWriteConfirmationDetails]:
        """æ™ºèƒ½ç¡®è®¤æœºåˆ¶ - å€Ÿé‰´Gemini CLIè®¾è®¡"""
        
        # è‡ªåŠ¨æ¨¡å¼æ£€æŸ¥
        if self.approval_mode in [ApprovalMode.AUTO_WRITE, ApprovalMode.AUTO_ALL]:
            return False
        
        path = Path(params["path"]).resolve()
        content = params["content"]
        mode = params.get("mode", "overwrite")
        # å¤„ç†æ ¼å¼å‚æ•°
        format_param = params.get("format")
        if format_param and isinstance(format_param, str):
            try:
                format = FileFormat(format_param.lower())
            except ValueError:
                format = self._detect_format(path)
        else:
            format = format_param if format_param else self._detect_format(path)
        
        # æ£€æŸ¥è·¯å¾„å®‰å…¨æ€§
        if not self._is_path_allowed(path):
            # å§‹ç»ˆéœ€è¦ç¡®è®¤å±é™©è·¯å¾„
            return self._create_confirmation_details(
                path, content, mode, format,
                title=self._('file_write_dangerous_path', default="âš ï¸ å±é™©è·¯å¾„: {path}", path=path),
                risk_level="high"
            )
        
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œç”Ÿæˆdiff
        file_diff = None
        if path.exists() and mode == "overwrite":
            try:
                existing_content = path.read_text(encoding=params.get("encoding", "utf-8"))
                file_diff = self._generate_diff(existing_content, content, path.name)
            except:
                file_diff = self._('file_write_cannot_read_existing', default="[æ— æ³•è¯»å–ç°æœ‰æ–‡ä»¶å†…å®¹]")
        
        # è·å–å…ƒæ•°æ®
        metadata = params.get("metadata", {})
        
        return FileWriteConfirmationDetails(
            title=self._get_confirmation_title(path, mode, format),
            file_path=str(path),
            file_diff=file_diff,
            content_preview=self._preview_content(content, format),
            estimated_size=self._format_size(len(content.encode('utf-8'))),
            format=format,
            data_source_sql=metadata.get("source_sql"),
            affected_tables=metadata.get("source_tables"),
            row_count=metadata.get("row_count"),
            allow_overwrite=(mode == "overwrite"),
            append_mode=(mode == "append")
        )
    
    async def execute(
        self,
        params: Dict[str, Any],
        signal: AbortSignal,
        update_output: Optional[Any] = None
    ) -> ToolResult:
        """æ‰§è¡Œæ–‡ä»¶å†™å…¥"""
        start_time = datetime.now()
        path = Path(params["path"]).resolve()
        content = params["content"]
        mode = params.get("mode", "overwrite")
        # å¤„ç†æ ¼å¼å‚æ•°ï¼šå¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰æˆ– FileFormat æšä¸¾ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
        format_param = params.get("format")
        if format_param:
            # å¦‚æœç”¨æˆ·æä¾›äº†æ ¼å¼ï¼Œè½¬æ¢ä¸ºæšä¸¾
            if isinstance(format_param, str):
                try:
                    format = FileFormat(format_param.lower())
                except ValueError:
                    return ToolResult(
                        error=self._('file_write_invalid_format', default="Invalid format: {format}. Supported formats: {supported}", format=format_param, supported=', '.join([f.value for f in FileFormat]))
                    )
            else:
                format = format_param
        else:
            # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
            format = self._detect_format(path)
        
        encoding_param = params.get("encoding", "auto")
        compression = params.get("compression", "none")
        
        # å¤„ç†ç¼–ç  - æ”¯æŒè‡ªåŠ¨æ£€æµ‹
        if encoding_param == "auto":
            try:
                from ..utils.encoding_utils import get_system_encoding
                encoding = get_system_encoding()
            except:
                encoding = "utf-8"
        else:
            encoding = encoding_param
        
        try:
            # è·¯å¾„å®‰å…¨æ£€æŸ¥
            if not self._is_path_allowed(path):
                return ToolResult(
                    error=self._('file_write_access_denied', default="Access denied: {path} is outside allowed directories", path=path)
                )
            
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            path.parent.mkdir(parents=True, exist_ok=True)
            
            # æ£€æŸ¥æ¨¡å¼
            if mode == "create_new" and path.exists():
                return ToolResult(
                    error=self._('file_write_already_exists', default="File already exists: {path}", path=path)
                )
            
            # æµå¼åé¦ˆå¼€å§‹
            if update_output:
                update_output(self._('file_write_progress', default="ğŸ“ æ­£åœ¨å†™å…¥{format}æ–‡ä»¶...\nğŸ“ è·¯å¾„: {path}\nğŸ“Š å¤§å°: {size}", format=format.value.upper(), path=path, size=self._format_size(len(content.encode('utf-8')))))
            
            # æ ¹æ®æ ¼å¼å¤„ç†å†…å®¹
            formatted_content = await self._format_content(content, format)
            
            # å†™å…¥æ–‡ä»¶
            if compression != "none":
                bytes_written = await self._write_compressed(path, formatted_content, compression, mode)
            else:
                bytes_written = await self._write_normal(path, formatted_content, encoding, mode)
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            
            # æ„å»ºç»“æœ
            operation_result = FileOperationResult(
                success=True,
                file_path=str(path),
                operation="append" if mode == "append" else "write",
                bytes_processed=bytes_written,
                lines_processed=formatted_content.count('\n') + 1,
                duration_ms=duration_ms,
                format=format,
                encoding=encoding,
                compression=compression if compression != "none" else None
            )
            
            # è¿”å›åˆ†å±‚ç»“æœ
            return self._create_success_result(operation_result, params)
            
        except Exception as e:
            return ToolResult(
                error=self._('file_write_failed', default="Failed to write file: {error}", error=str(e)),
                llm_content=self._('file_write_failed_llm', default="Error writing to {path}: {error}\nType: {type}", path=path, error=str(e), type=type(e).__name__)
            )
    
    # === ç§æœ‰æ–¹æ³• ===
    
    def _is_path_allowed(self, path: Path) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•å†…"""
        for allowed_path in self.allowed_paths:
            allowed = Path(allowed_path).resolve()
            try:
                path.relative_to(allowed)
                return True
            except ValueError:
                continue
        return False
    
    def _get_system_paths(self, config) -> list:
        """åŠ¨æ€æ£€æµ‹ç³»ç»Ÿå¹¶è¿”å›åˆé€‚çš„è®¿é—®è·¯å¾„ - çœŸæ­£çš„çµæ´»æ€§"""
        paths = []
        
        # æ™ºèƒ½æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•ï¼ˆå¾€ä¸Šæ‰¾åˆ°åŒ…å«packagesçš„ç›®å½•ï¼‰
        working_dir = Path(config.get_working_dir())
        current_dir = working_dir
        
        # å‘ä¸ŠæŸ¥æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
        while current_dir.parent != current_dir:  # æ²¡åˆ°æ ¹ç›®å½•
            if (current_dir / 'packages').exists() or (current_dir / 'pyproject.toml').exists():
                paths.append(str(current_dir))
                break
            current_dir = current_dir.parent
        
        # å¦‚æœæ²¡æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œè‡³å°‘åŒ…å«å·¥ä½œç›®å½•
        paths.append(config.get_working_dir())
        
        # ç”¨æˆ·ä¸»ç›®å½• - è·¨å¹³å°é€šç”¨
        home_dir = os.path.expanduser("~")
        if home_dir and os.path.exists(home_dir):
            paths.append(home_dir)
        
        # æ ¹æ®ç³»ç»Ÿå¹³å°åŠ¨æ€æ·»åŠ æ ¹è·¯å¾„
        import platform
        system = platform.system().lower()
        
        if system == "windows":
            # Windows: åŠ¨æ€æ£€æµ‹æ‰€æœ‰å¯ç”¨é©±åŠ¨å™¨
            import string
            for drive in string.ascii_uppercase:
                drive_path = f"{drive}:\\"
                if os.path.exists(drive_path):
                    paths.append(drive_path)
        
        elif system == "darwin":  # macOS
            paths.extend([
                "/",              # æ ¹ç›®å½•
                "/Users",         # ç”¨æˆ·ç›®å½•
                "/Applications",  # åº”ç”¨ç¨‹åº
                "/Volumes",       # æŒ‚è½½ç‚¹
            ])
        
        elif system == "linux":
            paths.extend([
                "/",              # æ ¹ç›®å½•
                "/home",          # ç”¨æˆ·ç›®å½•
                "/mnt",           # æŒ‚è½½ç‚¹ (WSLç­‰)
                "/media",         # åª’ä½“æŒ‚è½½
                "/opt",           # å¯é€‰è½¯ä»¶
                "/tmp",           # ä¸´æ—¶ç›®å½•
            ])
        
        else:
            # æœªçŸ¥ç³»ç»Ÿï¼Œä½¿ç”¨é€šç”¨è·¯å¾„
            if os.path.exists("/"):
                paths.append("/")
            # å°è¯•æ£€æµ‹å¸¸è§æŒ‚è½½ç‚¹
            for mount_point in ["/mnt", "/media", "/Volumes"]:
                if os.path.exists(mount_point):
                    paths.append(mount_point)
        
        # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„è·¯å¾„ï¼Œä¿ç•™çœŸå®å¯è®¿é—®çš„
        return [p for p in paths if os.path.exists(p)]
    
    def _detect_format(self, path: Path) -> FileFormat:
        """æ™ºèƒ½æ£€æµ‹æ–‡ä»¶æ ¼å¼ - ä¸ä»…ä¾èµ–æ‰©å±•å"""
        ext = path.suffix.lower()
        
        # é¦–å…ˆå°è¯•æ‰©å±•ååŒ¹é…
        for format, extensions in self.FORMAT_EXTENSIONS.items():
            if ext in extensions:
                return format
        
        # å¦‚æœæ²¡æœ‰æ‰©å±•åæˆ–æœªçŸ¥æ‰©å±•åï¼ŒåŸºäºè·¯å¾„åç§°æ™ºèƒ½æ¨æµ‹
        name_lower = path.name.lower()
        if 'data' in name_lower or 'export' in name_lower:
            return FileFormat.CSV  # æ•°æ®å¯¼å‡ºé»˜è®¤CSV
        elif 'report' in name_lower:
            return FileFormat.MARKDOWN  # æŠ¥å‘Šé»˜è®¤Markdown
        elif 'script' in name_lower:
            return FileFormat.SQL  # è„šæœ¬é»˜è®¤SQL
        
        # é»˜è®¤ä¸ºæ–‡æœ¬æ ¼å¼
        return FileFormat.TEXT
    
    def _generate_diff(self, old_content: str, new_content: str, filename: str) -> str:
        """ç”ŸæˆUnified Diffæ ¼å¼çš„å·®å¼‚ - å€Ÿé‰´Gemini CLI"""
        old_lines = old_content.splitlines(keepends=True)
        new_lines = new_content.splitlines(keepends=True)
        
        diff = difflib.unified_diff(
            old_lines,
            new_lines,
            fromfile=self._('file_write_diff_current', default="{filename} (å½“å‰)", filename=filename),
            tofile=self._('file_write_diff_proposed', default="{filename} (æè®®)", filename=filename),
            lineterm=''
        )
        
        return ''.join(diff)
    
    def _preview_content(self, content: str, format: FileFormat) -> str:
        """ç”Ÿæˆå†…å®¹é¢„è§ˆ"""
        max_preview = 500
        
        if format == FileFormat.JSON:
            try:
                data = json.loads(content)
                preview = json.dumps(data, indent=2, ensure_ascii=False)[:max_preview]
            except:
                preview = content[:max_preview]
        elif format == FileFormat.CSV:
            lines = content.split('\n')[:10]
            preview = '\n'.join(lines)
        else:
            preview = content[:max_preview]
        
        if len(content) > max_preview:
            preview += self._('file_write_content_truncated', default="\n... [å‰©ä½™å†…å®¹çœç•¥]")
        
        return preview
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"
    
    def _get_confirmation_title(self, path: Path, mode: str, format: FileFormat) -> str:
        """ç”Ÿæˆç¡®è®¤æ ‡é¢˜"""
        # æ›´çµæ´»çš„æ ‡é¢˜ç”Ÿæˆï¼Œé¿å…ç¡¬ç¼–ç ä¸­æ–‡
        if mode == "overwrite" and path.exists():
            return self._('file_write_confirm_overwrite', default="Confirm overwriting {filename}", filename=path.name)
        elif mode == "append":
            return self._('file_write_confirm_append', default="Confirm appending to {filename}", filename=path.name)
        else:
            return self._('file_write_confirm_create', default="Confirm creating {filename}", filename=path.name)
    
    async def _format_content(self, content: str, format: FileFormat) -> str:
        """æ ¹æ®æ ¼å¼æ™ºèƒ½å¤„ç†å†…å®¹"""
        if format == FileFormat.JSON:
            # ç¾åŒ–JSON
            try:
                data = json.loads(content)
                return json.dumps(data, indent=2, ensure_ascii=False)
            except:
                return content
        
        elif format == FileFormat.SQL:
            # æ·»åŠ SQLæ³¨é‡Šå¤´
            header = self._('file_write_sql_header', default="-- Generated by DbRheo at {timestamp}\n-- {separator}\n\n", timestamp=datetime.now().isoformat(), separator="=" * 50)
            return header + content
        
        elif format == FileFormat.MARKDOWN:
            # ç¡®ä¿æ ‡é¢˜æ ¼å¼æ­£ç¡®
            if not content.startswith('#'):
                return self._('file_write_markdown_header', default="# Data Export Report\n\nGenerated at: {timestamp}\n\n{content}", timestamp=datetime.now().isoformat(), content=content)
            return content
        
        return content
    
    async def _write_normal(self, path: Path, content: str, encoding: str, mode: str) -> int:
        """æ™®é€šæ–‡ä»¶å†™å…¥"""
        file_mode = 'a' if mode == "append" else 'w'
        
        async with aiofiles.open(path, mode=file_mode, encoding=encoding) as f:
            await f.write(content)
        
        return len(content.encode(encoding))
    
    async def _write_compressed(self, path: Path, content: str, compression: str, mode: str) -> int:
        """å‹ç¼©æ–‡ä»¶å†™å…¥"""
        import gzip
        import bz2
        import lzma
        
        # æ·»åŠ å‹ç¼©æ‰©å±•å
        compressed_path = path.with_suffix(path.suffix + f'.{compression}')
        
        # é€‰æ‹©å‹ç¼©æ–¹æ³•
        compress_func = {
            'gzip': gzip.compress,
            'bz2': bz2.compress,
            'xz': lzma.compress
        }.get(compression, gzip.compress)
        
        # å‹ç¼©å†…å®¹
        compressed_data = compress_func(content.encode('utf-8'))
        
        # å†™å…¥æ–‡ä»¶
        file_mode = 'ab' if mode == "append" else 'wb'
        async with aiofiles.open(compressed_path, mode=file_mode) as f:
            await f.write(compressed_data)
        
        return len(compressed_data)
    
    def _create_success_result(self, result: FileOperationResult, params: Dict[str, Any]) -> ToolResult:
        """åˆ›å»ºæˆåŠŸç»“æœ"""
        path = Path(result.file_path)
        metadata = params.get("metadata", {})
        
        # æ„å»ºæ‘˜è¦
        summary_parts = [
            f"Wrote {self._format_size(result.bytes_processed)}",
            f"to {path.name}"
        ]
        if result.compression:
            summary_parts.append(self._('file_write_compression_note', default="(å‹ç¼©: {compression})", compression=result.compression))
        summary = " ".join(summary_parts)
        
        # æ„å»º LLM å†…å®¹
        llm_content = f"""File successfully written:
- Path: {result.file_path}
- Format: {result.format.value if result.format else 'unknown'}
- Size: {self._format_size(result.bytes_processed)}
- Lines: {result.lines_processed}
- Duration: {result.duration_ms:.1f}ms"""
        
        if metadata.get("source_sql"):
            llm_content += f"\n- Source: SQL query"
            if metadata.get("row_count"):
                llm_content += f"\n- Rows exported: {metadata['row_count']}"
        
        # æ„å»ºç”¨æˆ·å±•ç¤º
        icon = {
            FileFormat.CSV: 'ğŸ“Š',
            FileFormat.JSON: 'ğŸ“‹',
            FileFormat.SQL: 'ğŸ—„ï¸',
            FileFormat.MARKDOWN: 'ğŸ“',
            FileFormat.EXCEL: 'ğŸ“Š'
        }.get(result.format, 'ğŸ“„')
        
        display_lines = [
            self._('file_write_written', default="{icon} å·²å†™å…¥ {filename}", icon=icon, filename=path.name),
            self._('file_write_size', default="ğŸ’¾ å¤§å°: {size}", size=self._format_size(result.bytes_processed)),
            self._('file_write_location', default="ğŸ“ ä½ç½®: {location}", location=path.parent)
        ]
        
        if result.compression:
            display_lines.append(self._('file_write_compression', default="ğŸ—œï¸ å‹ç¼©: {compression}", compression=result.compression))
        
        if result.duration_ms and result.duration_ms > 1000:
            duration_sec = result.duration_ms/1000
            display_lines.append(self._('file_write_duration', default="â±ï¸ è€—æ—¶: {duration:.1f}ç§’", duration=duration_sec))
        
        return ToolResult(
            summary=summary,
            llm_content=llm_content,
            return_display="\n".join(display_lines)
        )
    
    def _create_confirmation_details(
        self,
        path: Path,
        content: str,
        mode: str,
        format: FileFormat,
        title: str,
        risk_level: str = "normal"
    ) -> FileWriteConfirmationDetails:
        """åˆ›å»ºç¡®è®¤è¯¦æƒ…"""
        return FileWriteConfirmationDetails(
            title=title,
            file_path=str(path),
            content_preview=self._preview_content(content, format),
            estimated_size=self._format_size(len(content.encode('utf-8'))),
            format=format,
            allow_overwrite=(mode == "overwrite"),
            append_mode=(mode == "append")
        )
