"""
ç½‘ç»œæœç´¢å·¥å…· - è®©Agentèƒ½å¤Ÿè·å–æœ€æ–°ä¿¡æ¯
"""

import aiohttp
from typing import Dict, Any, Optional, List, Protocol
from abc import ABC, abstractmethod
import json
from ..types.tool_types import ToolResult
from ..types.core_types import AbortSignal
from .base import Tool
from ..config.base import AgentConfig


class SearchResult:
    """æœç´¢ç»“æœçš„é€šç”¨æ ¼å¼"""
    def __init__(self, title: str, url: str, snippet: str, **kwargs):
        self.title = title
        self.url = url
        self.snippet = snippet
        self.metadata = kwargs  # é¢å¤–çš„å…ƒæ•°æ®ï¼Œä¿æŒçµæ´»æ€§


class SearchBackend(ABC):
    """æœç´¢åç«¯çš„æŠ½è±¡æ¥å£ - æ”¯æŒæœªæ¥æ‰©å±•åˆ°ä¸åŒçš„æœç´¢å¼•æ“æˆ–AIæ¨¡å‹"""
    
    @abstractmethod
    async def search(self, query: str, max_results: int = 5, **kwargs) -> List[SearchResult]:
        """æ‰§è¡Œæœç´¢å¹¶è¿”å›ç»“æœ"""
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """è·å–åç«¯åç§°"""
        pass


class DuckDuckGoBackend(SearchBackend):
    """DuckDuckGoæœç´¢åç«¯ - æ— éœ€APIå¯†é’¥"""
    
    def get_name(self) -> str:
        return "DuckDuckGo"
    
    async def search(self, query: str, max_results: int = 5, **kwargs) -> List[SearchResult]:
        """ä½¿ç”¨DuckDuckGoè¿›è¡Œæœç´¢"""
        import re
        from urllib.parse import quote
        
        # DuckDuckGo HTMLæœç´¢
        url = f"https://html.duckduckgo.com/html/?q={quote(query)}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers) as response:
                    if response.status != 200:
                        raise Exception(f"Search request failed with status {response.status}")
                    
                    html = await response.text()
                    
                    # è°ƒè¯•ï¼šä¿å­˜HTMLåˆ°æ–‡ä»¶ä»¥ä¾¿åˆ†æ
                    import os
                    if os.getenv('DBRHEO_DEBUG_SEARCH', '').lower() == 'true':
                        with open('search_debug.html', 'w', encoding='utf-8') as f:
                            f.write(html)
                        print(f"[DEBUG] HTML saved to search_debug.html, length: {len(html)}")
                    
                    # æ”¹è¿›çš„HTMLè§£æ - æ›´çµæ´»çš„æ­£åˆ™è¡¨è¾¾å¼
                    results = []
                    
                    # å°è¯•å¤šç§æ¨¡å¼åŒ¹é…ç»“æœ
                    patterns = [
                        # æ ‡å‡†ç»“æœæ¨¡å¼
                        r'<a class="result__a"[^>]*href="([^"]+)"[^>]*>(.*?)</a>.*?<a class="result__snippet"[^>]*>(.*?)</a>',
                        # å¤‡ç”¨æ¨¡å¼1
                        r'<h2 class="result__title">.*?<a[^>]*href="([^"]+)"[^>]*>(.*?)</a>.*?</h2>.*?<a class="result__snippet"[^>]*>(.*?)</a>',
                        # å¤‡ç”¨æ¨¡å¼2 - æ›´å®½æ¾
                        r'<a[^>]*class="[^"]*result[^"]*"[^>]*href="([^"]+)"[^>]*>(.*?)</a>'
                    ]
                    
                    for pattern in patterns:
                        matches = re.findall(pattern, html, re.DOTALL)
                        if matches:
                            for match in matches[:max_results]:
                                if len(match) >= 3:
                                    url, title, snippet = match[0], match[1], match[2]
                                elif len(match) == 2:
                                    url, title = match[0], match[1]
                                    snippet = "No description available"
                                else:
                                    continue
                                    
                                # æ¸…ç†HTMLæ ‡ç­¾
                                title = re.sub(r'<[^>]+>', '', title).strip()
                                snippet = re.sub(r'<[^>]+>', '', snippet).strip()
                                
                                if title and url:  # ç¡®ä¿æœ‰æ ‡é¢˜å’ŒURL
                                    results.append(SearchResult(
                                        title=title,
                                        url=url,
                                        snippet=snippet,
                                        source="duckduckgo"
                                    ))
                            
                            if results:  # å¦‚æœæ‰¾åˆ°ç»“æœï¼Œåœæ­¢å°è¯•å…¶ä»–æ¨¡å¼
                                break
                    
                    # è°ƒè¯•ï¼šæ‰“å°æ‰¾åˆ°çš„ç»“æœæ•°é‡
                    if os.getenv('DBRHEO_DEBUG_SEARCH', '').lower() == 'true':
                        print(f"[DEBUG] Found {len(results)} results")
                        for i, r in enumerate(results[:2]):  # åªæ‰“å°å‰2ä¸ª
                            print(f"[DEBUG] Result {i}: {r.title} - {r.url[:50]}...")
                    
                    return results
                    
        except Exception as e:
            # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Œä¿æŒå¥å£®æ€§
            print(f"DuckDuckGo search error: {str(e)}")
            return []


class BingSearchBackend(SearchBackend):
    """Bingæœç´¢åç«¯ - éœ€è¦APIå¯†é’¥ï¼ˆé¢„ç•™æ¥å£ï¼‰"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
    
    def get_name(self) -> str:
        return "Bing"
    
    async def search(self, query: str, max_results: int = 5, **kwargs) -> List[SearchResult]:
        """ä½¿ç”¨Bing APIè¿›è¡Œæœç´¢"""
        # é¢„ç•™æ¥å£ï¼Œæœªæ¥å®ç°
        url = "https://api.bing.microsoft.com/v7.0/search"
        headers = {
            'Ocp-Apim-Subscription-Key': self.api_key,
        }
        params = {
            'q': query,
            'count': max_results
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = []
                        for item in data.get('webPages', {}).get('value', []):
                            results.append(SearchResult(
                                title=item.get('name', ''),
                                url=item.get('url', ''),
                                snippet=item.get('snippet', ''),
                                source="bing"
                            ))
                        return results
                    else:
                        return []
        except Exception:
            return []


class WebSearchTool(Tool):
    """
    ç½‘ç»œæœç´¢å·¥å…·ï¼Œè®©Agentèƒ½å¤Ÿè·å–å®æ—¶ä¿¡æ¯
    æ”¯æŒå¤šç§æœç´¢å¼•æ“åç«¯
    """
    
    def __init__(self, config: AgentConfig, i18n=None):
        # å…ˆä¿å­˜i18nå®ä¾‹ï¼Œä»¥ä¾¿åœ¨åˆå§‹åŒ–æ—¶ä½¿ç”¨
        self._i18n = i18n
        super().__init__(
            name="web_search",
            display_name=self._('web_search_tool_name', default="ç½‘ç»œæœç´¢") if i18n else "ç½‘ç»œæœç´¢",
            description="Searches the web with automatic query refinement and content fetching capabilities. Provides comprehensive search results from multiple sources with intelligent result filtering and summarization.",
            parameter_schema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The search query"
                    },
                    "max_results": {
                        "type": "integer",
                        "description": "Maximum number of results to return",
                        "minimum": 1,
                        "maximum": 10
                    }
                },
                "required": ["query"]
            },
            is_output_markdown=True,
            can_update_output=True,
            should_summarize_display=True,
            i18n=i18n  # ä¼ é€’i18nç»™åŸºç±»
        )
        self.config = config
        # çµæ´»çš„åç«¯é…ç½®ç³»ç»Ÿ
        self.backend = self._initialize_backend()
    
    def validate_tool_params(self, params: Dict[str, Any]) -> Optional[str]:
        """éªŒè¯å‚æ•°"""
        query = params.get("query", "")
        if not query:
            return self._('web_search_query_empty', default="Search query cannot be empty")
        return None
    
    def get_description(self, params: Dict[str, Any]) -> str:
        """è·å–æ“ä½œæè¿°"""
        query = params.get("query", "")
        max_results = params.get("max_results", 5)
        # ç¡®ä¿ max_results æ˜¯æ•´æ•°
        try:
            max_results = int(max_results)
        except (TypeError, ValueError):
            max_results = 5
        return self._('web_search_description', default="Search web for: {query}... (max {max_results} results)", query=query[:50], max_results=max_results)
    
    async def should_confirm_execute(self, params: Dict[str, Any], signal: AbortSignal) -> Optional[Any]:
        """ç½‘ç»œæœç´¢é€šå¸¸ä¸éœ€è¦ç¡®è®¤"""
        return False
        
    def _initialize_backend(self) -> SearchBackend:
        """åˆå§‹åŒ–æœç´¢åç«¯ - æ”¯æŒçµæ´»é…ç½®"""
        backend_type = self.config.get("search_backend", "duckduckgo")
        
        if backend_type == "duckduckgo":
            return DuckDuckGoBackend()
        elif backend_type == "bing":
            api_key = self.config.get("bing_api_key")
            if not api_key:
                # å¦‚æœæ²¡æœ‰é…ç½®Bing APIå¯†é’¥ï¼Œå›é€€åˆ°DuckDuckGo
                return DuckDuckGoBackend()
            return BingSearchBackend(api_key)
        else:
            # é»˜è®¤ä½¿ç”¨DuckDuckGo
            return DuckDuckGoBackend()
    
    async def execute(
        self,
        params: Dict[str, Any],
        signal: AbortSignal,
        update_output: Optional[Any] = None
    ) -> ToolResult:
        """æ‰§è¡Œç½‘ç»œæœç´¢ - ä½¿ç”¨é…ç½®çš„åç«¯"""
        query = params.get("query", "")
        max_results = params.get("max_results", 5)
        # ç¡®ä¿ max_results æ˜¯æ•´æ•°
        try:
            max_results = int(max_results)
        except (TypeError, ValueError):
            max_results = 5
        
        try:
            # æµå¼åé¦ˆ - æ˜¾ç¤ºä½¿ç”¨çš„æœç´¢å¼•æ“
            if update_output:
                update_output(self._('web_search_searching', default="ğŸ” Searching with {backend}: {query}...", backend=self.backend.get_name(), query=query))
            
            # ä½¿ç”¨æŠ½è±¡åç«¯è¿›è¡Œæœç´¢
            results = await self.backend.search(query, max_results)
            
            if not results:
                # å¦‚æœä¸»åç«¯å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨åç«¯
                if hasattr(self, '_fallback_backend'):
                    if update_output:
                        update_output(self._('web_search_fallback', default="ğŸ”„ Trying fallback search..."))
                    results = await self._fallback_backend.search(query, max_results)
                
                if not results:
                    return ToolResult(
                        summary=self._('web_search_no_results', default="No results found"),
                        llm_content=self._('web_search_no_results_llm', default="No search results found for '{query}' using {backend}", query=query, backend=self.backend.get_name()),
                        return_display=self._('web_search_no_results_display', default="No results found")
                    )
            
            # æ ¼å¼åŒ–ç»“æœ - ä½¿ç”¨é€šç”¨çš„SearchResultå¯¹è±¡
            llm_content = self._format_results_for_llm(results, query)
            display_content = self._format_results_for_display(results)
            
            return ToolResult(
                summary=self._('web_search_found_results', default="Found {count} results for '{query}'", count=len(results), query=query),
                llm_content=llm_content,
                return_display=display_content
            )
            
        except Exception as e:
            # æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_msg = self._('web_search_failed', default="Search failed using {backend}: {error}", backend=self.backend.get_name(), error=str(e))
            return ToolResult(
                error=error_msg,
                llm_content=error_msg,
                return_display=self._('web_search_failed_display', default="Search failed")
            )
    
    def _set_fallback_backend(self, backend: SearchBackend):
        """è®¾ç½®å¤‡ç”¨æœç´¢åç«¯"""
        self._fallback_backend = backend
    
    def _format_results_for_llm(self, results: List[SearchResult], query: str) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœä¾›LLMä½¿ç”¨ - æ”¯æŒSearchResultå¯¹è±¡"""
        content = self._('web_search_results_header', default="Web search results for '{query}':\n\n", query=query)
        
        for i, result in enumerate(results, 1):
            content += f"{i}. {result.title}\n"
            content += self._('web_search_result_url', default="   URL: {url}\n", url=result.url)
            content += self._('web_search_result_summary', default="   Summary: {summary}\n", summary=result.snippet)
            
            # å¦‚æœæœ‰é¢å¤–çš„å…ƒæ•°æ®ï¼Œä¹ŸåŒ…å«è¿›å»
            if result.metadata:
                for key, value in result.metadata.items():
                    if key != 'source':  # sourceå·²ç»åœ¨backendåç§°ä¸­ä½“ç°
                        content += f"   {key.capitalize()}: {value}\n"
            
            content += "\n"
            
        content += self._('web_search_results_footer', default="\nBased on these search results, I can provide relevant information about the query.")
        return content
    
    def _format_results_for_display(self, results: List[SearchResult]) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœä¾›ç”¨æˆ·æ˜¾ç¤º - æ”¯æŒSearchResultå¯¹è±¡"""
        if not results:
            return self._('web_search_no_results_text', default="No search results found.")
            
        lines = [self._('web_search_display_header', default="ğŸ” Search Results (via {backend}):\n", backend=self.backend.get_name())]
        
        for i, result in enumerate(results, 1):
            lines.append(f"{i}. **{result.title}**")
            
            # æ™ºèƒ½æˆªæ–­æ‘˜è¦
            snippet = result.snippet
            if len(snippet) > 150:
                snippet = snippet[:147] + "..."
            lines.append(f"   {snippet}")
            
            lines.append(f"   ğŸ”— {result.url}\n")
            
        return "\n".join(lines)